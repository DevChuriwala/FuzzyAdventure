{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EWEDuJcbOxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0e20986e-baa3-43f1-d893-d43c6dd88901"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug  8 19:29:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    31W / 250W |    927MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyDODoaWC6KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB43g3rJxvgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, classes):\n",
        "    super(LeNet, self).__init__()\n",
        "\n",
        "    self.extract = nn.Sequential(\n",
        "        nn.Conv2d(1, 10, 5), #LeNet-5 used 6 filters, I've used 10 filters\n",
        "        nn.BatchNorm2d(10),\n",
        "        nn.ReLU(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(p = 0.2),\n",
        "        nn.Conv2d(10,20,5), #LeNet-5 used 16 filters, I've used 20 filters\n",
        "        nn.BatchNorm2d(20),\n",
        "        nn.ReLU(),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(p = 0.2),        \n",
        "    )\n",
        "\n",
        "    self.classify = nn.Sequential(\n",
        "        nn.Linear(in_features=320, out_features=50), \n",
        "        #nn.BatchNorm1d(320),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=50, out_features=classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.extract(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    logits = self.classify(x)\n",
        "    return logits"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWcHbC0Hxw8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform=transforms.Compose([\n",
        "           transforms.RandomHorizontalFlip(),                        \n",
        "           transforms.ToTensor(),\n",
        "           transforms.Normalize((0.1307,), (0.3081,))\n",
        "           ])\n",
        "\n",
        "test_transform=transforms.Compose([\n",
        "           transforms.ToTensor(),\n",
        "           transforms.Normalize((0.1307,), (0.3081,))\n",
        "           ])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='/content/data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.MNIST(root='/content/data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=16)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=16)\n",
        "\n",
        "dataset_sizes = {'train':len(trainset), 'val':len(testset)}\n",
        "dataloaders = {'train':trainloader, 'val':testloader}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFmTOBK1xyc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        since = time.time()\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and test phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to test mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            time_elapsed = time.time() - since\n",
        "            print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "            time_elapsed // 60, time_elapsed % 60))            \n",
        "            \n",
        "            torch.save(model.state_dict(), '/content/MNIST_LeNet_Epoch_' + str(epoch+1) + '.pth')\n",
        "\n",
        "        print()\n",
        "    return model"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMM0VuqJx033",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LeNet(10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.15, momentum=0.9, nesterov=True)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRjF4a-wH5zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prev_state = torch.load('/content/CIFAR10_LeNet_Epoch_35.pth')\n",
        "# model.load_state_dict(prev_state)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsxceKzSx2aQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ffebab4-2c4e-4f36-bd60-cf25852cda1a"
      },
      "source": [
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=50)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "----------\n",
            "train Loss: 0.3015 Acc: 0.9041\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0988 Acc: 0.9683\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n",
            "train Loss: 0.1353 Acc: 0.9571\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0705 Acc: 0.9774\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n",
            "train Loss: 0.1072 Acc: 0.9664\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0578 Acc: 0.9803\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n",
            "train Loss: 0.0942 Acc: 0.9699\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0460 Acc: 0.9852\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n",
            "train Loss: 0.0904 Acc: 0.9715\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0490 Acc: 0.9841\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n",
            "train Loss: 0.0803 Acc: 0.9748\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0462 Acc: 0.9848\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n",
            "train Loss: 0.0795 Acc: 0.9749\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0424 Acc: 0.9862\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n",
            "train Loss: 0.0753 Acc: 0.9765\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0463 Acc: 0.9845\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n",
            "train Loss: 0.0738 Acc: 0.9766\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0419 Acc: 0.9857\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n",
            "train Loss: 0.0703 Acc: 0.9778\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0396 Acc: 0.9866\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n",
            "train Loss: 0.0524 Acc: 0.9834\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0342 Acc: 0.9891\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n",
            "train Loss: 0.0494 Acc: 0.9842\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0342 Acc: 0.9890\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n",
            "train Loss: 0.0473 Acc: 0.9845\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0340 Acc: 0.9880\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n",
            "train Loss: 0.0481 Acc: 0.9844\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0330 Acc: 0.9890\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n",
            "train Loss: 0.0458 Acc: 0.9852\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0309 Acc: 0.9896\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n",
            "train Loss: 0.0461 Acc: 0.9850\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0324 Acc: 0.9891\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n",
            "train Loss: 0.0424 Acc: 0.9865\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0313 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n",
            "train Loss: 0.0437 Acc: 0.9859\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0305 Acc: 0.9897\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n",
            "train Loss: 0.0434 Acc: 0.9863\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0322 Acc: 0.9888\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n",
            "train Loss: 0.0419 Acc: 0.9864\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0330 Acc: 0.9884\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n",
            "train Loss: 0.0441 Acc: 0.9860\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0309 Acc: 0.9896\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n",
            "train Loss: 0.0423 Acc: 0.9866\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0306 Acc: 0.9898\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n",
            "train Loss: 0.0433 Acc: 0.9855\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0303 Acc: 0.9896\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n",
            "train Loss: 0.0408 Acc: 0.9869\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0298 Acc: 0.9898\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n",
            "train Loss: 0.0432 Acc: 0.9860\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0295 Acc: 0.9901\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n",
            "train Loss: 0.0415 Acc: 0.9864\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9897\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n",
            "train Loss: 0.0418 Acc: 0.9858\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9894\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n",
            "train Loss: 0.0421 Acc: 0.9862\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0307 Acc: 0.9892\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n",
            "train Loss: 0.0417 Acc: 0.9867\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9899\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n",
            "train Loss: 0.0410 Acc: 0.9868\n",
            "Training complete in 0m 6s\n",
            "val Loss: 0.0302 Acc: 0.9898\n",
            "Training complete in 0m 7s\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n",
            "train Loss: 0.0409 Acc: 0.9868\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0300 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n",
            "train Loss: 0.0416 Acc: 0.9860\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9899\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n",
            "train Loss: 0.0413 Acc: 0.9866\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0303 Acc: 0.9897\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n",
            "train Loss: 0.0417 Acc: 0.9863\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0303 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9866\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n",
            "train Loss: 0.0408 Acc: 0.9866\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0303 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n",
            "train Loss: 0.0419 Acc: 0.9864\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0299 Acc: 0.9901\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n",
            "train Loss: 0.0413 Acc: 0.9863\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9869\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9865\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0300 Acc: 0.9901\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n",
            "train Loss: 0.0421 Acc: 0.9859\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0300 Acc: 0.9898\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n",
            "train Loss: 0.0390 Acc: 0.9872\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9901\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n",
            "train Loss: 0.0426 Acc: 0.9857\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9902\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n",
            "train Loss: 0.0417 Acc: 0.9864\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0300 Acc: 0.9901\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n",
            "train Loss: 0.0426 Acc: 0.9862\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n",
            "train Loss: 0.0405 Acc: 0.9867\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9899\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n",
            "train Loss: 0.0426 Acc: 0.9861\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9899\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n",
            "train Loss: 0.0404 Acc: 0.9863\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0302 Acc: 0.9900\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n",
            "train Loss: 0.0426 Acc: 0.9861\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9901\n",
            "Training complete in 0m 6s\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n",
            "train Loss: 0.0421 Acc: 0.9863\n",
            "Training complete in 0m 5s\n",
            "val Loss: 0.0301 Acc: 0.9899\n",
            "Training complete in 0m 6s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}